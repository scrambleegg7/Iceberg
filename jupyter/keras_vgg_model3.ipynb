{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, ELU, Add\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sys import platform\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import fbeta_score\n",
    "from PIL import Image, ImageStat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, cv2\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.ndimage import laplace, sobel\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from numpy import matrix\n",
    "from numpy import linalg\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "if platform == \"linux\":\n",
    "    dataDir = \"/home/donchan/Documents/myData/KaggleData/Iceberg\"\n",
    "else:\n",
    "    dataDir = \"/Users/donchan/Documents/myData/KaggleData/Iceberg\"\n",
    "train_data = os.path.join(dataDir,\"data/processed/train.json\")\n",
    "test_data = os.path.join(dataDir,\"data/processed/test.json\")\n",
    "\n",
    "print(\"load data...\")\n",
    "\n",
    "\n",
    "train = pd.read_json(train_data)\n",
    "test = pd.read_json(test_data)\n",
    "#train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "#train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "print(\"done!\")\n",
    "\n",
    "angle = train.inc_angle.copy()\n",
    "angle = angle.replace('na',np.nan)\n",
    "\n",
    "angle_median = angle.median()\n",
    "angle_mean = angle.mean()\n",
    "angle = angle.astype(np.float32).fillna(angle_median)\n",
    "\n",
    "test_angle = test.inc_angle.copy()\n",
    "test_angle = test_angle.replace('na',np.nan)\n",
    "\n",
    "test_angle_median = test_angle.median()\n",
    "test_angle_mean = test_angle.mean()\n",
    "test_angle = test_angle.astype(np.float32).fillna(test_angle_median)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(imgs): \n",
    "    return imgs / 100. +  0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rescale = rescale(X_train)\n",
    "X_test_rescale = rescale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8911840198>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f891184aa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "\n",
    "x1_shape = x_band1.shape\n",
    "x2_shape = x_band2.shape\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "stand_x_band1 = mm_scaler.fit_transform(x_band1.reshape(-1,1))\n",
    "stand_x_band2 = mm_scaler.fit_transform(x_band2.reshape(-1,1))\n",
    "x_band1_st = stand_x_band1.reshape(x1_shape)\n",
    "x_band2_st = stand_x_band2.reshape(x2_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1604, 75, 75), (1604, 75, 75), (1604, 75, 75), (1604, 75, 75))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_band1.shape,x_band2.shape,x_band1_st.shape,x_band2_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x123767290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFJCAYAAAChG+XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWURExGIUziIiIhajcBYREbGY/x8+6jeVvAc32wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123a85650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f65b056ce48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFKCAYAAABRtSXvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREGmHIEhERaYQhS0REpJH/D5J9ktvjvgSdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65b055a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(stand_x_band1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_train = np.array(train.inc_angle)\n",
    "y_train = np.array(train[\"is_iceberg\"])\n",
    "\n",
    "\n",
    "#X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "#                          , X_band_2[:, :, :, np.newaxis]\n",
    "#                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 75, 75) (8424, 75, 75)\n"
     ]
    }
   ],
   "source": [
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "\n",
    "x1_shape = x_band1.shape\n",
    "x2_shape = x_band2.shape\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "stand_x_band1 = mm_scaler.fit_transform(x_band1.reshape(-1,1))\n",
    "stand_x_band2 = mm_scaler.fit_transform(x_band2.reshape(-1,1))\n",
    "x_band1_st = stand_x_band1.reshape(x1_shape)\n",
    "x_band2_st = stand_x_band2.reshape(x2_shape)\n",
    "print(x_band1_st.shape,x_band2_st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1 + x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check shape of X_train X_angle_train y_train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1604, 75, 75, 3), (1604,), (1604,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_angle_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Full Layer vgg16 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553459712/553467096 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading VGG 16 model to eliminate Fc layer # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58875904/58889256 [============================>.] - ETA: 0sModel loaded.\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(512)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outout layer should be 4 x 4 x 512, but it does not show shape information because of input image is missing ? ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    input_meta = Input(shape=[1], name='angle')\n",
    "    #input_meta_bn = BatchNormalization(momentum=bn_model)(input_meta)\n",
    "    \n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    \n",
    "    base_model.load_weights(\"../vgg16_weights.h5\")\n",
    "\n",
    "\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    #print(\"\",x)\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    #print(\"top_cnn shape after Global MaxPooling\", top_cnn.shape)\n",
    "\n",
    "    dense_layer= Dense(256, activation='relu', name='fc2')(x)\n",
    "    dense_layer = Dropout(0.2)(dense_layer)  # drop out 0 - 0.5\n",
    "    predictions = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "    #model = Model(input=base_model.input, output=predictions)\n",
    "    model = Model(input=[base_model.input, input_meta], output=predictions)\n",
    "\n",
    "    for i, layer in enumerate(model.layers[:18]):\n",
    "        if layer.trainable:\n",
    "            print(layer.name)\n",
    "            print(\"layer trainable %d : True -> False\" % i)\n",
    "            layer.trainable = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (Can't locate attribute: 'layer_names')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-98e1902305d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-029d89a08a45>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                  input_shape=X_train.shape[1:], classes=1)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../vgg16_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2617\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3054\u001b[0m             \u001b[0mfiltered_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3056\u001b[0;31m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layer_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3057\u001b[0m     \u001b[0mfiltered_layer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028290543/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028290543/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/h5py/_hl/attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028290543/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028290543/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open (/home/ilan/minonda/conda-bld/h5py_1490028290543/work/h5py/h5a.c:2343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Can't open attribute (Can't locate attribute: 'layer_names')\""
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 True\n",
      "9 True\n",
      "10 True\n",
      "11 True\n",
      "12 True\n",
      "13 True\n",
      "14 True\n",
      "15 True\n",
      "16 True\n",
      "17 True\n",
      "18 True\n",
      "19 True\n",
      "20 True\n",
      "21 True\n",
      "22 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers[:25]):\n",
    "    print(i, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2), Dimension(2), Dimension(512)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_26 (Glo (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,846,273\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,846,273\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore last layer block5_pool #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"block5_pool_2/MaxPool:0\", shape=(?, 2, 2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = base_model.get_layer('block5_pool').output\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_cnn shape after Global MaxPooling (?, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "print(\"top_cnn shape after Global MaxPooling\", top_cnn.shape)\n",
    "\n",
    "#I tried fine-tuned with resnet50 as well, \n",
    "#but like William said, these images are quite different ... \n",
    "#What I've tried is to resize the image and fine-tune the last fc layers \n",
    "#and add one more fc layer to train, \n",
    "#in which the pre-trained model is helpful \n",
    "#but not useful (acc~70%, loss > .6, too bad...). \n",
    "#Maybe try to fine tune to from more later bottleneck layer(s) can have much performance boost (I did not try it)\n",
    "\n",
    "\n",
    "#Actually In my opinion, \n",
    "#we can use pretrained model. \n",
    "#However, the things we need to fine-tune should be whole network, \n",
    "#which means all the pretrained weight we got is just initial parameter for this problem, \n",
    "#the goal is to easier find global minimum. \n",
    "#However, you definitely can modify the models based on your own deep learning knowledge. \n",
    "#I made some experiments and found modified pretrained model is better than some simple CNN model.\n",
    "\n",
    "\n",
    "dense_layer= Dense(256, activation='relu', name='fc2')(x)\n",
    "dense_layer = Dropout(0.2)(dense_layer)  # drop out 0 - 0.5\n",
    "predictions = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#dense_ayer = ELU()(BatchNormalization(momentum=bn_model)( Dense(512, activation=None)(top_cnn) ))\n",
    "#dense_ayer = Dropout(0.5)(dense_ayer)\n",
    "#dense_ayer = ELU()(BatchNormalization(momentum=bn_model)( Dense(256, activation=None)(dense_ayer) ))\n",
    "#dense_ayer = Dropout(0.5)(dense_ayer)\n",
    "\n",
    "# 2 for One Hot code for Binary \n",
    "#output = Dense(2, activation=\"softmax\")(dense_ayer)\n",
    "\n",
    "\n",
    "\n",
    "#model = Model([input_1],  output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement last layer (after block5) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=10):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myBaseCrossTrain(X_train, target_train):\n",
    "    \n",
    "    K = 4\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        #file_path = \"%s_model_weights.hdf5\"%j\n",
    "        #os.remove(file_path)\n",
    "        #callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        \n",
    "        print('\\n===================FOLD=',j+1)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        angle_meta_cv = angle[train_idx]\n",
    "        angle_meta_holdout = angle[test_idx]\n",
    "        \n",
    "        \n",
    "        file_path = \"keras_vgg16_model3_weights_%s.hdf5\" % j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10)\n",
    "\n",
    "        \n",
    "        #galaxyModel=getVggModel()\n",
    "        galaxyModel=get_model()\n",
    "\n",
    "        galaxyModel.fit([X_train_cv, angle_meta_cv ], y_train_cv,\n",
    "                  batch_size=24,\n",
    "                  epochs=80,\n",
    "                  verbose=1,\n",
    "                  validation_data=([X_holdout, angle_meta_holdout ], Y_holdout),\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv, angle_meta_cv ], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout, angle_meta_holdout], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout, angle_meta_holdout ] )\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "\n",
    "    print('\\nLog Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1\n",
      "layer trainable 1 : True -> False\n",
      "block1_conv2\n",
      "layer trainable 2 : True -> False\n",
      "block1_pool\n",
      "layer trainable 3 : True -> False\n",
      "block2_conv1\n",
      "layer trainable 4 : True -> False\n",
      "block2_conv2\n",
      "layer trainable 5 : True -> False\n",
      "block2_pool\n",
      "layer trainable 6 : True -> False\n",
      "block3_conv1\n",
      "layer trainable 7 : True -> False\n",
      "block3_conv2\n",
      "layer trainable 8 : True -> False\n",
      "block3_conv3\n",
      "layer trainable 9 : True -> False\n",
      "block3_pool\n",
      "layer trainable 10 : True -> False\n",
      "block4_conv1\n",
      "layer trainable 11 : True -> False\n",
      "block4_conv2\n",
      "layer trainable 12 : True -> False\n",
      "block4_conv3\n",
      "layer trainable 13 : True -> False\n",
      "block4_pool\n",
      "layer trainable 14 : True -> False\n",
      "block5_conv1\n",
      "layer trainable 15 : True -> False\n",
      "block5_conv2\n",
      "layer trainable 16 : True -> False\n",
      "block5_conv3\n",
      "layer trainable 17 : True -> False\n",
      "Train on 1202 samples, validate on 402 samples\n",
      "Epoch 1/80\n",
      "1202/1202 [==============================] - 3s - loss: 0.8105 - acc: 0.5158 - val_loss: 0.6892 - val_acc: 0.5522\n",
      "Epoch 2/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.7241 - acc: 0.5516 - val_loss: 0.6153 - val_acc: 0.6294\n",
      "Epoch 3/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.6569 - acc: 0.6123 - val_loss: 0.5683 - val_acc: 0.6866\n",
      "Epoch 4/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.6269 - acc: 0.6240 - val_loss: 0.5419 - val_acc: 0.6915\n",
      "Epoch 5/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5848 - acc: 0.6830 - val_loss: 0.5236 - val_acc: 0.7065\n",
      "Epoch 6/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5658 - acc: 0.6864 - val_loss: 0.5094 - val_acc: 0.7239\n",
      "Epoch 7/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5332 - acc: 0.7171 - val_loss: 0.4998 - val_acc: 0.7289\n",
      "Epoch 8/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5312 - acc: 0.7180 - val_loss: 0.4924 - val_acc: 0.7388\n",
      "Epoch 9/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5222 - acc: 0.7263 - val_loss: 0.4840 - val_acc: 0.7463\n",
      "Epoch 10/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4925 - acc: 0.7463 - val_loss: 0.4805 - val_acc: 0.7562\n",
      "Epoch 11/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.5067 - acc: 0.7471 - val_loss: 0.4736 - val_acc: 0.7562\n",
      "Epoch 12/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4728 - acc: 0.7496 - val_loss: 0.4700 - val_acc: 0.7687\n",
      "Epoch 13/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4995 - acc: 0.7396 - val_loss: 0.4649 - val_acc: 0.7736\n",
      "Epoch 14/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4709 - acc: 0.7562 - val_loss: 0.4624 - val_acc: 0.7687\n",
      "Epoch 15/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4695 - acc: 0.7729 - val_loss: 0.4585 - val_acc: 0.7662\n",
      "Epoch 16/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4711 - acc: 0.7737 - val_loss: 0.4552 - val_acc: 0.7637\n",
      "Epoch 17/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4691 - acc: 0.7837 - val_loss: 0.4513 - val_acc: 0.7711\n",
      "Epoch 18/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4599 - acc: 0.7779 - val_loss: 0.4479 - val_acc: 0.7811\n",
      "Epoch 19/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4552 - acc: 0.7737 - val_loss: 0.4460 - val_acc: 0.7786\n",
      "Epoch 20/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4617 - acc: 0.7812 - val_loss: 0.4442 - val_acc: 0.7761\n",
      "Epoch 21/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4582 - acc: 0.7762 - val_loss: 0.4416 - val_acc: 0.7836\n",
      "Epoch 22/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4509 - acc: 0.7804 - val_loss: 0.4385 - val_acc: 0.7736\n",
      "Epoch 23/80\n",
      "1202/1202 [==============================] - 1s - loss: 0.4456 - acc: 0.7720 - val_loss: 0.4376 - val_acc: 0.7836\n",
      "Epoch 24/80\n",
      "  24/1202 [..............................] - ETA: 0s - loss: 0.3817 - acc: 0.7917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-88316f9ac153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyBaseCrossTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-fd144f97a732>\u001b[0m in \u001b[0;36mmyBaseCrossTrain\u001b[0;34m(X_train, target_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_holdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_meta_holdout\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                   callbacks=callbacks)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#Getting the Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_results = myBaseCrossTrain(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make submission file #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': test_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.075891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.389140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.998434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.047113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d    0.075891\n",
       "1  4023181e    0.389140\n",
       "2  b20200e4    0.004431\n",
       "3  e7f018bb    0.998434\n",
       "4  4371c8c3    0.047113"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"output/keras_vgg16_model3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.26628294],\n",
       "       [ 0.26628294,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(X_angle_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot code y_train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oh = preprocessing.OneHotEncoder(sparse=False)\n",
    "y_train_oh = oh.fit_transform( y_train[:,np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5,  5.5,  9.5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(12).reshape(3,4).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training and Validation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train_oh, y_valid_oh = train_test_split(X_train, y_train_oh, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1283, 75, 75, 3), (321, 75, 75, 3), (1283, 2), (321, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, y_train_oh.shape, y_valid_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    851\n",
       "1    753\n",
       "Name: is_iceberg, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"is_iceberg\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras Model Definiton #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(p_activation=\"elu\", k_size = (5,5), dropout=0.25):\n",
    "    bn_model = 0.99\n",
    "    #p_activation = \"elu\"\n",
    "    input_1 = Input(shape=(75, 75, 3), name=\"X_1\")\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    \n",
    "    img_1 = Conv2D(32, kernel_size = k_size, activation=p_activation, padding=\"same\") ((BatchNormalization(momentum=bn_model))(input_1))\n",
    "    img_1 = Conv2D(32, kernel_size = k_size, activation=p_activation, padding=\"same\") (img_1)\n",
    "    img_1 = MaxPooling2D((2,2)) (img_1)\n",
    "    img_1 = Dropout(dropout)(img_1)\n",
    "\n",
    "    img_1 = Conv2D(64, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(img_1))\n",
    "    img_1 = Conv2D(64, kernel_size = k_size, activation=p_activation, padding=\"same\")(img_1)\n",
    "    img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "    img_1 = Dropout(dropout)(img_1)    \n",
    "    \n",
    "    print(\"img1 shape\", img_1.shape)\n",
    "\n",
    "    img_resid = Conv2D(128, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(img_1))\n",
    "    img_resid = Conv2D(128, kernel_size = k_size, activation=p_activation, padding=\"same\")(img_resid)\n",
    "    img_resid = Dropout(dropout)(img_resid)    \n",
    "    print(\"img_resid shape1\", img_resid.shape)\n",
    "    \n",
    "    img_resid = Conv2D(64, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(img_resid))\n",
    "    img_resid = Conv2D(64, kernel_size = k_size, activation=p_activation, padding=\"same\")(img_resid)\n",
    "    print(\"img_resid shape2\", img_resid.shape)\n",
    "\n",
    "    cnn_resid_added = Add()([img_1, img_resid])\n",
    "    print(\"cnn_resid shape\", cnn_resid_added.shape)\n",
    "    \n",
    "    top_cnn = Conv2D(128, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(cnn_resid_added))\n",
    "    top_cnn = Conv2D(128, kernel_size = k_size, activation=p_activation, padding=\"same\")(top_cnn)\n",
    "    top_cnn = MaxPooling2D((2,2)) (top_cnn)\n",
    "    top_cnn = Conv2D(256, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(top_cnn))\n",
    "    top_cnn = Conv2D(256, kernel_size = k_size, activation=p_activation, padding=\"same\")(top_cnn)\n",
    "    top_cnn = Dropout(0.25)(top_cnn)\n",
    "    top_cnn = MaxPooling2D((2,2)) (top_cnn)\n",
    "    top_cnn = Conv2D(512, kernel_size = k_size, activation=p_activation, padding=\"same\")((BatchNormalization(momentum=bn_model))(top_cnn))\n",
    "    top_cnn = Conv2D(512, kernel_size = k_size, activation=p_activation, padding=\"same\")(top_cnn)\n",
    "    top_cnn = Dropout(dropout)(top_cnn)\n",
    "    top_cnn = MaxPooling2D((2,2)) (top_cnn)\n",
    "    \n",
    "    top_cnn = GlobalMaxPooling2D()(top_cnn)\n",
    "    print(\"top_cnn shape\", top_cnn.shape)\n",
    "\n",
    "    dense_ayer = ELU()(BatchNormalization(momentum=bn_model)( Dense(512, activation=None)(top_cnn) ))\n",
    "    dense_ayer = Dropout(0.5)(dense_ayer)\n",
    "    dense_ayer = ELU()(BatchNormalization(momentum=bn_model)( Dense(256, activation=None)(dense_ayer) ))\n",
    "    dense_ayer = Dropout(0.5)(dense_ayer)\n",
    "    \n",
    "    # 2 for One Hot code for Binary \n",
    "    output = Dense(2, activation=\"softmax\")(dense_ayer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model([input_1],  output)\n",
    "    #optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    \n",
    "    #model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    #model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"categorical_accuracy\"])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img1 shape (?, 18, 18, 64)\n",
      "img_resid shape1 (?, 18, 18, 128)\n",
      "img_resid shape2 (?, 18, 18, 64)\n",
      "cnn_resid shape (?, 18, 18, 64)\n",
      "top_cnn shape (?, 512)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "X_1 (InputLayer)                 (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchNo (None, 75, 75, 3)     12          X_1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1023 (Conv2D)             (None, 75, 75, 32)    896         batch_normalization_658[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1024 (Conv2D)             (None, 75, 75, 32)    9248        conv2d_1023[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_366 (MaxPooling2D) (None, 37, 37, 32)    0           conv2d_1024[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_512 (Dropout)            (None, 37, 37, 32)    0           max_pooling2d_366[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchNo (None, 37, 37, 32)    128         dropout_512[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1025 (Conv2D)             (None, 37, 37, 64)    18496       batch_normalization_659[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1026 (Conv2D)             (None, 37, 37, 64)    36928       conv2d_1025[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_367 (MaxPooling2D) (None, 18, 18, 64)    0           conv2d_1026[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_513 (Dropout)            (None, 18, 18, 64)    0           max_pooling2d_367[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchNo (None, 18, 18, 64)    256         dropout_513[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1027 (Conv2D)             (None, 18, 18, 128)   73856       batch_normalization_660[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1028 (Conv2D)             (None, 18, 18, 128)   147584      conv2d_1027[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_514 (Dropout)            (None, 18, 18, 128)   0           conv2d_1028[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchNo (None, 18, 18, 128)   512         dropout_514[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1029 (Conv2D)             (None, 18, 18, 64)    73792       batch_normalization_661[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1030 (Conv2D)             (None, 18, 18, 64)    36928       conv2d_1029[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "add_74 (Add)                     (None, 18, 18, 64)    0           dropout_513[0][0]                \n",
      "                                                                   conv2d_1030[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchNo (None, 18, 18, 64)    256         add_74[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1031 (Conv2D)             (None, 18, 18, 128)   73856       batch_normalization_662[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1032 (Conv2D)             (None, 18, 18, 128)   147584      conv2d_1031[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_368 (MaxPooling2D) (None, 9, 9, 128)     0           conv2d_1032[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchNo (None, 9, 9, 128)     512         max_pooling2d_368[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1033 (Conv2D)             (None, 9, 9, 256)     295168      batch_normalization_663[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1034 (Conv2D)             (None, 9, 9, 256)     590080      conv2d_1033[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_515 (Dropout)            (None, 9, 9, 256)     0           conv2d_1034[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_369 (MaxPooling2D) (None, 4, 4, 256)     0           dropout_515[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchNo (None, 4, 4, 256)     1024        max_pooling2d_369[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1035 (Conv2D)             (None, 4, 4, 512)     1180160     batch_normalization_664[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1036 (Conv2D)             (None, 4, 4, 512)     2359808     conv2d_1035[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_516 (Dropout)            (None, 4, 4, 512)     0           conv2d_1036[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_370 (MaxPooling2D) (None, 2, 2, 512)     0           dropout_516[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_74 (GlobalM (None, 512)           0           max_pooling2d_370[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_220 (Dense)                (None, 512)           262656      global_max_pooling2d_74[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchNo (None, 512)           2048        dense_220[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_147 (ELU)                    (None, 512)           0           batch_normalization_665[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_517 (Dropout)            (None, 512)           0           elu_147[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_221 (Dense)                (None, 256)           131328      dropout_517[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_666 (BatchNo (None, 256)           1024        dense_221[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_148 (ELU)                    (None, 256)           0           batch_normalization_666[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_518 (Dropout)            (None, 256)           0           elu_148[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_222 (Dense)                (None, 2)             514         dropout_518[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 5,444,654\n",
      "Trainable params: 5,441,768\n",
      "Non-trainable params: 2,886\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(dropout=0.5,k_size=(3,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50 ## change this to 80\n",
    "#steps_per_epoch=np.power(2,14) /batch_size ## change to 2^14\n",
    "\n",
    "#print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback definition #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=10):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "file_path = \"keras_model2_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,75,75,32]\n\t [[Node: conv2d_1023/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](batch_normalization_658/cond/Merge, conv2d_1023/kernel/read)]]\n\t [[Node: loss_73/mul/_21137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_7073_loss_73/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv2d_1023/convolution', defined at:\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-cea55d126f84>\", line 1, in <module>\n    model = get_model(dropout=0.5,k_size=(3,3))\n  File \"<ipython-input-45-86bf7e30ed38>\", line 7, in get_model\n    img_1 = Conv2D(32, kernel_size = k_size, activation=p_activation, padding=\"same\") ((BatchNormalization(momentum=bn_model))(input_1))\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3164, in conv2d\n    data_format='NHWC')\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 664, in op\n    name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,75,75,32]\n\t [[Node: conv2d_1023/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](batch_normalization_658/cond/Merge, conv2d_1023/kernel/read)]]\n\t [[Node: loss_73/mul/_21137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_7073_loss_73/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,75,75,32]\n\t [[Node: conv2d_1023/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](batch_normalization_658/cond/Merge, conv2d_1023/kernel/read)]]\n\t [[Node: loss_73/mul/_21137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_7073_loss_73/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3f810cb4e0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,75,75,32]\n\t [[Node: conv2d_1023/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](batch_normalization_658/cond/Merge, conv2d_1023/kernel/read)]]\n\t [[Node: loss_73/mul/_21137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_7073_loss_73/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv2d_1023/convolution', defined at:\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-cea55d126f84>\", line 1, in <module>\n    model = get_model(dropout=0.5,k_size=(3,3))\n  File \"<ipython-input-45-86bf7e30ed38>\", line 7, in get_model\n    img_1 = Conv2D(32, kernel_size = k_size, activation=p_activation, padding=\"same\") ((BatchNormalization(momentum=bn_model))(input_1))\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3164, in conv2d\n    data_format='NHWC')\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 664, in op\n    name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/donchan/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,75,75,32]\n\t [[Node: conv2d_1023/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](batch_normalization_658/cond/Merge, conv2d_1023/kernel/read)]]\n\t [[Node: loss_73/mul/_21137 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_7073_loss_73/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "gen_images = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,)\n",
    "        #fill_mode='nearest')\n",
    "\n",
    "model.fit_generator(\n",
    "    \n",
    "        gen_images.flow(x_train,y_train_oh,batch_size=batch_size),\n",
    "        steps_per_epoch=np.ceil(32.0 * float(y_train_oh.shape[0]) / float(batch_size)),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_valid,y_valid_oh),\n",
    "        validation_steps=np.ceil(32.0 * float(y_valid_oh.shape[0]) / float(batch_size)), \n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/321 [============================>.] - ETA: 0sTest loss: 0.26210459931\n",
      "Test accuracy: 0.890965732087\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath=file_path)\n",
    "score = model.evaluate(x_valid, y_valid_oh, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "#x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "#X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "#                          , x_band2[:, :, :, np.newaxis]\n",
    "#                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8424 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test], verbose=1, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.695578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.113909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.966803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.020416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d    0.695578\n",
       "1  4023181e    0.113909\n",
       "2  b20200e4    0.000026\n",
       "3  e7f018bb    0.966803\n",
       "4  4371c8c3    0.020416"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"output/keras_model2_basic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# test for Cross Validation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_onehot = np_utils.to_categorical( y_train )\n",
    "num_classes = y_onehot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_activation = [\"elu\",\"relu\", \"sigmoid\"]\n",
    "k_size = [(3,3), (5,5)]\n",
    "dropout = [0.25, 0.50, 0.75 ]\n",
    "nb_epoch = [10, 25, 50]\n",
    "batch_size = [16, 32, 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=get_model, verbose=1)\n",
    "param_grid = dict(p_activation=p_activation, \n",
    "                  k_size=k_size, \n",
    "                  dropout=dropout, \n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_CNN = input_img_norm %>%\n",
    "    layer_conv_2d(32, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "    layer_batch_normalization(momentum = 0.99) %>%\n",
    "    layer_activation_elu() %>%\n",
    "    layer_max_pooling_2d(c(2,2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_conv_2d(64, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "    layer_batch_normalization(momentum = 0.99) %>%\n",
    "    layer_activation_elu() %>%\n",
    "    layer_max_pooling_2d(c(2,2)) %>%\n",
    "    layer_dropout(0.25) \n",
    "\n",
    "## first residual\n",
    "input_CNN_residual = input_CNN %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_conv_2d(128, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_activation_elu() %>%\n",
    "  layer_dropout(0.25) %>%\n",
    "  layer_conv_2d(64, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_activation_elu()\n",
    "\n",
    "input_CNN_residual = layer_add(list(input_CNN_residual,input_CNN))\n",
    "\n",
    "top_CNN = input_CNN_residual %>%\n",
    "  layer_conv_2d(128, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_activation_elu() %>%\n",
    "  layer_max_pooling_2d(c(2,2)) %>%\n",
    "  layer_conv_2d(256, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_activation_elu() %>%\n",
    "  layer_dropout(0.25) %>%\n",
    "  layer_max_pooling_2d(c(2,2)) %>%\n",
    "  layer_conv_2d(512, kernel_size = kernel_size,padding = \"same\") %>%\n",
    "  layer_batch_normalization(momentum = 0.99) %>%\n",
    "  layer_activation_elu() %>%\n",
    "  layer_dropout(0.25) %>%\n",
    "  layer_max_pooling_2d(c(2,2)) %>%\n",
    "  layer_global_max_pooling_2d()\n",
    "\n",
    "outputs = top_CNN %>%\n",
    "    layer_dense(512,activation = NULL) %>%\n",
    "    layer_batch_normalization(momentum = 0.99) %>%\n",
    "    layer_activation_elu() %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(256,activation = NULL) %>%\n",
    "    layer_batch_normalization(momentum = 0.99) %>%\n",
    "    layer_activation_elu() %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(2,activation = \"softmax\") ## not sure using softmax is the right thing to do...\n",
    "    \n",
    "model <- keras_model(inputs = list(input_img), outputs = list(outputs))\n",
    "\n",
    "model %>% compile(optimizer=optimizer_adam(lr = 0.001),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics = c(\"accuracy\"))\n",
    "\n",
    "summary(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
